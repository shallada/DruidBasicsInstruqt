slug: druid-architecture
id: udfhmyejqzoh
type: track
title: Druid Architecture
teaser: Learn about the Druid process architecture and how to deploy it
description: |-
  # Sandbox container

  This track helps you understand the components of the Druid architecture, which helps you deploy and manage a Druid cluster.
icon: https://cdn.instruqt.com/assets/templates/ubuntu.png
tags: []
owner: imply
developers:
- steve.halladay@imply.io
private: false
published: true
challenges:
- slug: 01-setup-master
  id: rz0nyjakolm7
  type: challenge
  title: Set Up the Master Server
  teaser: Learn how to deploy the Druid master server
  notes:
  - type: video
    url: https://www.youtube.com/embed/TjoKbcz5PGA
  assignment: |-
    <details>
      <summary style="color:cyan"><b>Are you new to these exercises? Click here for instructions.</b></summary>
    <hr style="background-color:cyan">
    <br>These exercises allow you to actually <i>do</i> the tasks involved in learning Druid within the comfort of your browser!<br><br>
    Click on the command boxes to copy the commands to your clipboard.
    Then, paste the commands in the terminal to execute them.<br><br>
    Some of the steps of the exercise will require using browser tabs external to the exercise tab.
    When necessary, the exercise will explain how to open these external tabs.
    When working in other browser tabs, you will want to switch back and forth between the tabs.<br><br>
    That's all there is to it! Enjoy!
    <hr style="background-color:cyan">
    </details>

    Our Druid deployment will use four servers.
    ![Druid Server Architecture](https://raw.githubusercontent.com/shallada/InstruqtImages/main/druid-architecture/servers.png)

    We need to install the Druid software and configure it on each of the servers.
    In this challenge, we'll deploy the master server and lay the foundation for the other servers.

    <details>
      <summary style="color:cyan">What are the tabs we'll use in this track? Click here to find out.</b></summary>
    <hr style="background-color:cyan">
    We will deploy Druid using four servers.
    In each challenge, as we set up another server, we will add another tab which will give you Bash shell access to the server.
    <br>
    <br>
    Besides the Bash shell tabs, there is one additional tab, which is an editor tab on the master server.
    We will use this editor to edit files on the master server and then copy them as needed to the other servers.
    <hr style="background-color:cyan">
    </details>


    Start by downloading the Druid distibution.

    ```
    wget https://ftp.wayne.edu/apache/druid/0.21.1/apache-druid-0.21.1-bin.tar.gz
    ```

    Unzip the downloaded file and move into the resulting directory.

    ```
    tar -xzf apache-druid-0.21.1-bin.tar.gz
    cd apache-druid-0.21.1
    ```

    In this challenge, we will be working with servers that are smaller than you would normally use in production.
    For educational purposes, these smaller servers will suffice.


    But to deploy on these smaller servers, we need to restrict the amount of memory the various processes use.
    To do this, we will use the same configuration files we used in the single server quickstart example.


    Let's review the changes that we will cause by using the quickstart configuration.

    ```
    diff /root/apache-druid-0.21.1/conf/druid/single-server/nano-quickstart/coordinator-overlord/jvm.config conf/druid/cluster/master/coordinator-overlord/jvm.config
    ```

    These changes show Java command options that will decrease the memory consumption.


    Now, let's copy this configuration file into our cluster configuration.

    ```
    cp conf/druid/single-server/nano-quickstart/coordinator-overlord/jvm.config conf/druid/cluster/master/coordinator-overlord
    ```

    We need to configure the servers so that they can discover each other.

    <details>
      <summary style="color:cyan">Want to know how the discovery process works? Click here.</b></summary>
    <hr style="background-color:cyan">
    <ol>
    <li>On each server, in the common configuration file, we set <i>druid.zk.service.host</i> to tell the server how to contact ZooKeeper</li>
    <li>In this same common configuration file we comment out <i>druid.host</i>, which forces the server to automatically determine its host name</li>
    <li>Each server contacts ZooKeeper and registers who and where they are</li>
    <li>Finally, ZooKeeper tells each of the servers how to contact other processes within the cluster</li>
    </ol>
    <hr style="background-color:cyan">
    </details>

    Click on the _Master-editor_ tab in the top-left corner of this screen.

    ![Click Master-editor tab](https://raw.githubusercontent.com/shallada/InstruqtImages/main/druid-architecture/ClickMasterEditor.png)

    Open the file: <i>/root/apache-druid-0.21.1/conf/druid/cluster/_common/common.runtime.properties</i>.

    ![Common Proper File Path](https://raw.githubusercontent.com/shallada/InstruqtImages/main/druid-architecture/CommonFilePath.png)

    Search for line _druid.host=localhost_ and comment the line out.

    Next, search for _druid.zk.service.host_ and change its value (which is currently _localhost_) to
    ```
    master-server:2181
    ```

    ![Change Values](https://raw.githubusercontent.com/shallada/InstruqtImages/main/druid-architecture/ChangeValuesMaster.png)

    Save the file by clicking on the file icon in the tab.

    ![Save File Changes](https://raw.githubusercontent.com/shallada/InstruqtImages/main/druid-architecture/SaveFileChanges.png)

    <hr style="background-color:cyan">
    <p><span style="color:cyan"><strong><em>NOTE:</em></strong></span> <i>Be sure to save the file.
    Modified files show a blue dot in the editor tab, so if you see the blue dot, you still need to save the file.</i>
    <hr style="background-color:cyan">


    Return the the Master-shell tab.

    ![Click Master-shell tab](https://raw.githubusercontent.com/shallada/InstruqtImages/main/druid-architecture/ClickMasterShell.png)


    Now, we can launch the master server.
    We will use _nohup_ here so that the process doesn't die when we move to the next challenge.

    ```
    nohup /root/apache-druid-0.21.1/bin/start-cluster-master-with-zk-server > /root/apache-druid-0.21.1/log.out 2> /root/apache-druid-0.21.1/log.err < /dev/null & disown
    ```

    Check that ZooKeeper and the coordinator processes are running (you should see two Java processes near the bottom of the list of processes).

    ```
    ps -ef
    ```

    We can make sure that the running master server is using our configuration changes by querying its status API.
    The following command queries the API for _druid.zk.service.host_, which is the setting we changed (you may have to wait a minute for the web server to initialize).

    ```
    curl master-server:8081/status/properties | jq | grep druid.zk.service.host
    ```

    We can also query the API to make sure that _druid.host_ is not set (because we commented it out).
    The following command should _not_ find _druid.hosts_ in the master-server properties.

    ```
    curl master-server:8081/status/properties | jq | grep druid.host
    ```

    You can find the log files for these processes here:

    ```
    tail var/sv/coordinator-overlord.log
    ```

    and here:

    ```
    tail var/sv/zk.log
    ```

    ## Great! You have deployed the master server.
  tabs:
  - title: Master-shell
    type: terminal
    hostname: master-server
  - title: Master-editor
    type: code
    hostname: master-server
    path: /root
  difficulty: basic
  timelimit: 6000
- slug: 02-data-server-1
  id: qniu2kdu7eeu
  type: challenge
  title: Set Up the First Data Server
  teaser: Learn how to deploy the first of two data servers
  notes:
  - type: video
    url: https://www.youtube.com/embed/VSrxVqh-8cI
  assignment: |-
    In this challenge we will deploy the first of two data servers named _data-server-1_.


    Download the Druid distibution.

    ```
    wget https://ftp.wayne.edu/apache/druid/0.21.1/apache-druid-0.21.1-bin.tar.gz

    ```

    Unzip the downloaded file and move into the resulting directory.

    ```
    tar -xzf apache-druid-0.21.1-bin.tar.gz
    cd apache-druid-0.21.1

    ```

    Again, we will be working with servers that are smaller than you would use in production.
    We need to restrict the amount of memory the various processes use.
    So, to cut back on memory usage, we will use the same configuration files we used in the single server quickstart example.


    Here are the commands you can use to see what changes we will be making to four different files.

    ```
    diff /root/apache-druid-0.21.1/conf/druid/single-server/nano-quickstart/historical/runtime.properties conf/druid/cluster/data/historical/runtime.properties
    ```


    ```
    diff /root/apache-druid-0.21.1/conf/druid/single-server/nano-quickstart/historical/jvm.config conf/druid/cluster/data/historical/jvm.config
    ```


    ```
    diff /root/apache-druid-0.21.1/conf/druid/single-server/nano-quickstart/middleManager/runtime.properties conf/druid/cluster/data/middleManager/runtime.properties
    ```


    ```
    diff /root/apache-druid-0.21.1/conf/druid/single-server/nano-quickstart/middleManager/jvm.config conf/druid/cluster/data/middleManager/jvm.config
    ```


    Let's copy these files into our cluster configuration.

    ```
    cp conf/druid/single-server/nano-quickstart/historical/* conf/druid/cluster/data/historical
    cp conf/druid/single-server/nano-quickstart/middleManager/* conf/druid/cluster/data/middleManager
    ```

    Now, let's copy the _common.runtime.properties_ file we edited in the first challenge to this server.
    Remember, this file tells the server how to contact ZooKeeper.

    ```
    scp -o StrictHostKeyChecking=no master-server:/root/apache-druid-0.21.1/conf/druid/cluster/_common/common.runtime.properties /root/apache-druid-0.21.1/conf/druid/cluster/_common/common.runtime.properties
    ```

    We are set to launch the first data server.
    Again, we'll use _nohup_ so that the processes continue to run when we move to the next challenge.

    ```
    nohup /root/apache-druid-0.21.1/bin/start-cluster-data-server > /root/apache-druid-0.21.1/log.out 2> /root/apache-druid-0.21.1/log.err < /dev/null & disown
    ```


    Check that the historical and middleManager processes are running.

    ```
    ps -ef | grep "java\-[8-8]" | awk 'NF{print $NF}'
    ```

    You can find the log files for these processes here:

    ```
    tail var/sv/historical.log
    ```

    and here:

    ```
    tail var/sv/middleManager.log
    ```

    ## Cool! You have deployed the first data server.
  tabs:
  - title: Data-1-shell
    type: terminal
    hostname: data-server-1
  - title: Master-shell
    type: terminal
    hostname: master-server
  - title: Master-editor
    type: code
    hostname: master-server
    path: /root
  difficulty: basic
  timelimit: 6000
- slug: 03-data-server-2
  id: o5qyksvmb8is
  type: challenge
  title: Set Up the Second Data Server
  teaser: Learn how to deploy the second of two data servers
  notes:
  - type: video
    url: https://www.youtube.com/embed/arsF6Ok4e-k
  assignment: |-
    In this challenge we will deploy the second of two data servers named _data-server-2_.
    This server works just like data-server-1.

    By adding more data servers, we not only increase the amount of storage, but we also bring more CPU to bare for query processing.


    Download the Druid distibution.

    ```
    wget https://ftp.wayne.edu/apache/druid/0.21.1/apache-druid-0.21.1-bin.tar.gz
    ```

    Unzip the downloaded file and move into the resulting directory.

    ```
    tar -xzf apache-druid-0.21.1-bin.tar.gz
    cd apache-druid-0.21.1
    ```

    Let's copy the files to change the configuration like we did with data-server-1.

    ```
    cp conf/druid/single-server/nano-quickstart/historical/* conf/druid/cluster/data/historical
    cp conf/druid/single-server/nano-quickstart/middleManager/* conf/druid/cluster/data/middleManager
    ```

    Again, let's copy the _common.runtime.properties_ file we edited in the first challenge so that the server knows how to contact ZooKeeper.

    ```
    scp -o StrictHostKeyChecking=no master-server:/root/apache-druid-0.21.1/conf/druid/cluster/_common/common.runtime.properties /root/apache-druid-0.21.1/conf/druid/cluster/_common/common.runtime.properties
    ```

    Now, we can launch the second data server.
    Again, we'll use _nohup_ so that the processes continue to run when we move to the next challenge.

    ```
    nohup /root/apache-druid-0.21.1/bin/start-cluster-data-server > /root/apache-druid-0.21.1/log.out 2> /root/apache-druid-0.21.1/log.err < /dev/null & disown
    ```


    Check that the historical and middleManager processes are running.

    ```
    ps -ef | grep "java\-[8-8]" | awk 'NF{print $NF}'
    ```

    ## Outstanding! You have deployed the second data server.
  tabs:
  - title: Data-2-shell
    type: terminal
    hostname: data-server-2
  - title: Data-1-shell
    type: terminal
    hostname: data-server-1
  - title: Master-shell
    type: terminal
    hostname: master-server
  - title: Master-editor
    type: code
    hostname: master-server
    path: /root
  difficulty: basic
  timelimit: 6000
- slug: 04-query-server
  id: 6qdcbszfasb6
  type: challenge
  title: Set Up the Query Server
  teaser: Learn how to deploy the query server
  notes:
  - type: video
    url: https://www.youtube.com/embed/GEJqq40NGFc
  assignment: |-
    In this challenge we will deploy the query server named _query-server_.


    Download the Druid distibution.

    ```
    wget https://ftp.wayne.edu/apache/druid/0.21.1/apache-druid-0.21.1-bin.tar.gz
    ```

    Unzip the downloaded file and move into the resulting directory.

    ```
    tar -xzf apache-druid-0.21.1-bin.tar.gz
    cd apache-druid-0.21.1
    ```


    Here are the commands you can use to see what changes we will be making to four different files.

    ```
    diff conf/druid/single-server/nano-quickstart/broker/runtime.properties conf/druid/cluster/query/broker/runtime.properties
    ```


    ```
    diff conf/druid/single-server/nano-quickstart/broker/jvm.config conf/druid/cluster/query/broker/jvm.config
    ```


    ```
    diff conf/druid/single-server/nano-quickstart/router/runtime.properties conf/druid/cluster/query/router/runtime.properties
    ```


    ```
    diff conf/druid/single-server/nano-quickstart/router/jvm.config conf/druid/cluster/query/router/jvm.config
    ```


    Let's copy these files into our cluster configuration.

    ```
    cp conf/druid/single-server/nano-quickstart/broker/* conf/druid/cluster/query/broker
    cp conf/druid/single-server/nano-quickstart/router/* conf/druid/cluster/query/router
    ```

    One last time, let's copy the _common.runtime.properties_ file we edited in the first challenge so that the server knows how to contact ZooKeeper.

    ```
    scp -o StrictHostKeyChecking=no master-server:/root/apache-druid-0.21.1/conf/druid/cluster/_common/common.runtime.properties /root/apache-druid-0.21.1/conf/druid/cluster/_common/common.runtime.properties
    ```

    Now, we can launch the query server.
    Again, we'll use _nohup_ so that the processes continue to run when we move to the next challenge.

    ```
    nohup /root/apache-druid-0.21.1/bin/start-cluster-query-server > /root/apache-druid-0.21.1/log.out 2> /root/apache-druid-0.21.1/log.err < /dev/null & disown
    ```


    Check that the broker and router processes are running.

    ```
    ps -ef | grep "java\-[8-8]" | awk 'NF{print $NF}'
    ```

    You can find the log files for these processes here:

    ```
    tail var/sv/broker.log
    ```

    and here:

    ```
    tail var/sv/router.log
    ```

    ## Wonderful! You have deployed the query server.
  tabs:
  - title: Query-shell
    type: terminal
    hostname: query-server
  - title: Data-2-shell
    type: terminal
    hostname: data-server-2
  - title: Data-1-shell
    type: terminal
    hostname: data-server-1
  - title: Master-shell
    type: terminal
    hostname: master-server
  - title: Master-editor
    type: code
    hostname: master-server
    path: /root
  difficulty: basic
  timelimit: 6000
- slug: 05-druid-ingest
  id: nckfsnpatf9h
  type: challenge
  title: Let's Ingest Data into Druid
  teaser: Learn how to ingest Druid data
  notes:
  - type: video
    url: https://www.youtube.com/embed/EfyJA80Hbxc
  assignment: |2-

    With Druid running, let's look at the Druid console.
    Click on the green _Open external window_ button in the middle of the adjacent window as shown.

    <hr style="background-color:cyan">
    <p><span style="color:cyan"><strong><em>NOTE:</em></strong></span> <i>During this challenge, you will need to switch back and forth between the Console tab and this challenge tab.</i></p>
    <hr style="background-color:cyan">

    ![Click console](https://raw.githubusercontent.com/shallada/InstruqtImages/main/druid-architecture/ClickConsole.png)

    Load data by clicking as shown.

    ![Load data](https://raw.githubusercontent.com/shallada/InstruqtImages/main/druid-architecture/LoadData.png)

    The console walks you through the ingestion steps.
    Since we are using example data, we can just accept the defaults by clickng the _Next:-_ buttons.

    ![Click next](https://raw.githubusercontent.com/shallada/InstruqtImages/main/druid-architecture/ClickWildly.png)

    <hr style="background-color:cyan">
    <p><span style="color:cyan"><strong><em>NOTE:</em></strong></span> <i>The focuses of this track is Druid deployment.
    So, we will not cover the details of ingestion.
    But, the purpose of the previous screens through which we wildly clicked was to build an ingestion specification.
    You can review the JSON ingestion specification on left side of this final screen.</i>
    <hr style="background-color:cyan">

    Finally, click _Submit_ to ingest the data.

    ![Click submit](https://raw.githubusercontent.com/shallada/InstruqtImages/main/druid-architecture/ClickSubmit.png)

    The ingestion takes a minute or so.
    You will know Druid has written the segments to deep storage when you see the _SUCCESS_ status.

    ![Wait for SUCCESS](https://raw.githubusercontent.com/shallada/InstruqtImages/main/try-it-out/WaitForSuccess.png)

    After Druid writes the segments to deep storage, it then loads the segments for querying.
    You can tell the segments are loaded and ready when you see this.

    ![Segments Loaded](https://raw.githubusercontent.com/shallada/InstruqtImages/main/try-it-out/SegmentsLoaded.png)



    ## Wow! You have ingested the data!
  tabs:
  - title: Console
    type: service
    hostname: query-server
    path: /
    port: 8888
    new_window: true
  - title: Query-shell
    type: terminal
    hostname: query-server
  - title: Data-2-shell
    type: terminal
    hostname: data-server-2
  - title: Data-1-shell
    type: terminal
    hostname: data-server-1
  - title: Master-shell
    type: terminal
    hostname: master-server
  - title: Master-editor
    type: code
    hostname: master-server
    path: /root
  difficulty: basic
  timelimit: 6000
- slug: 06-druid-query
  id: q3w7m4f35qwv
  type: challenge
  title: Let's Query Druid
  teaser: Learn how to query Druid data
  notes:
  - type: video
    url: https://www.youtube.com/embed/yJ1Od-gvn8M
  assignment: |-
    With Druid running and data ingested, let's return to the Druid console.
    Click on the browser tab containing the Druid Unified Console, or on the green _Open external window_ button in the middle of the adjacent window as shown.

    <hr style="background-color:cyan">
    <p><span style="color:cyan"><strong><em>NOTE:</em></strong></span> <i>During this challenge, you will need to switch back and forth between the Console tab and this challenge tab.</i></p>
    <hr style="background-color:cyan">

    ![Click console](https://raw.githubusercontent.com/shallada/InstruqtImages/main/druid-architecture/ClickConsole.png)

    This data is about updates to Wikipedia during a one day period.
    Both people and robots contributed to the updates.


    Suppose you want to know how updates vary for humans and robots over time.
    Here's a query that can help you answer that question.

    ```
    SELECT
      DATE_TRUNC('hour',"__time"),
      (AVG(commentLength) FILTER(WHERE isRobot=true)) as robots,
      (AVG(commentLength) FILTER(WHERE isRobot=false)) as humans
    FROM wikipedia
    GROUP BY 1
    ```

    Click on the _Query_ tab, paste the query in the console and run it as shown.
    Then, check out the results.

    ![Query Druid](https://raw.githubusercontent.com/shallada/InstruqtImages/main/druid-architecture/DruidQuery.png)


    ## Amazing! Druid queries are easy!
  tabs:
  - title: Console
    type: service
    hostname: query-server
    path: /
    port: 8888
    new_window: true
  - title: Query-shell
    type: terminal
    hostname: query-server
  - title: Data-2-shell
    type: terminal
    hostname: data-server-2
  - title: Data-1-shell
    type: terminal
    hostname: data-server-1
  - title: Master-shell
    type: terminal
    hostname: master-server
  - title: Master-editor
    type: code
    hostname: master-server
    path: /root
  difficulty: basic
  timelimit: 6000
checksum: "10956271004005613230"
_: ""
